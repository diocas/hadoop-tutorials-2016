{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import SQLContext\n",
    "import os\n",
    "\n",
    "# Use the Databricks CSV parser, this will automatically infer the schema.\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.databricks:spark-csv_2.10:1.4.0 pyspark-shell'\n",
    "sc = SparkContext(appName=\"CERN Spark ML tutorial\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "In this part of the tutorial we will discuss the process of feature selection, - normalization, and - engineering using Apache Spark. In contrast to the previous parts, we will **not** be using a Decision Tree, or an ensemble of decision trees (like a Random Forest) since these require no to little data preperation (like normalization) because of the model intrisics.\n",
    "\n",
    "However, other models, such as a Neural Network, profit from feature normalization since it will (most of the time) reduce the training time, and will not cause the hidden neurons to be saturated (and thus preventing numerical errors).\n",
    "\n",
    "Of course, like before, we will apply the same basic steps:\n",
    "1. Loading the dataset.\n",
    "2. Vectorizing the features.\n",
    "3. Transforming the string labels (\"s\" and \"b\") to indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Load the dataset.\n",
    "dataset = sqlContext.read.format('com.databricks.spark.csv')\\\n",
    "                    .options(header='true', inferSchema='true').load(\"training.csv\")\n",
    "# Keep a copy of the original dataset for later use.\n",
    "original_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# 2. Vectorize the features into the \"features\" column.\n",
    "features = dataset.columns\n",
    "features.remove('EventId')\n",
    "features.remove('Weight')\n",
    "features.remove('Label')\n",
    "\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "dataset = assembler.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, IndexToString\n",
    "from pyspark.sql.functions import rowNumber\n",
    "\n",
    "# 3. Transform the string labels to indices.\n",
    "labelIndexer = StringIndexer(inputCol=\"Label\", outputCol=\"label\").fit(dataset)\n",
    "dataset = labelIndexer.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset in a traing and test set for future model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(trainingSet, testSet) = dataset.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we transformed the original dataset in a format Apache Spark can understand, we will train a basic model which will act as a baseline. The metric we will apply to evaluate this model is the F1 score (https://en.wikipedia.org/wiki/F1_score). We would like to note that this metric is not the ideal metric for this dataset because of high noise in the dataset. However, other metrics like AUC (Area Under ROC curve: https://en.wikipedia.org/wiki/Receiver_operating_characteristic) are also not very suitable, as can be derrived from the documentation of the winning models.\n",
    "\n",
    "**note**: Due to time limitations we will not be able to train a decent model. However, we will try to show that feature normalization and engineering can indeed improve the performance of your model. Please feel free to modify the model and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define the structure of the Neural Network.\n",
    "numFeatures    = len(features)\n",
    "numClasses     = 2 # s, b\n",
    "# It is possibly to supply multiple hidden layers. E.g., [numFeatures, 10, 10, 10, numClasses]\n",
    "layers         = [numFeatures, 10, numClasses]\n",
    "\n",
    "# Define the learning algorithm (estimator).\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=5, blockSize=100000 ,layers=layers, seed=1234L)\n",
    "# Train the Neural Network on the training set.\n",
    "nnModel = trainer.fit(trainingSet)\n",
    "nnResult = nnModel.transform(testSet)\n",
    "\n",
    "# Evaluate the model performance using the F1 metric.\n",
    "predictionAndLabels = nnResult.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "print(\"F1:\" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Normalize the features with zero mean and unit standard deviation.\n",
    "standardScaler = StandardScaler(inputCol=\"features\", outputCol=\"features_normalized\", withStd=True, withMean=True)\n",
    "standardScalerModel = standardScaler.fit(dataset)\n",
    "\n",
    "normalized_dataset = standardScalerModel.transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, split the dataset into a training- and a testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingSet, testSet) = normalized_dataset.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check if the normalized features improve our model performance! Note that our feature column has now been renamed to **features_normalized**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define the structure of the Neural Network.\n",
    "numFeatures    = len(features)\n",
    "numClasses     = 2 # s, b\n",
    "layers         = [numFeatures, 10, numClasses]\n",
    "\n",
    "# Define the learning algorithm (estimator).\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=5, blockSize=100000 ,layers=layers,\\\n",
    "                                         seed=1234L, featuresCol=\"features_normalized\")\n",
    "# Train the Neural Network on the training set.\n",
    "nnModel = trainer.fit(trainingSet)\n",
    "nnResult = nnModel.transform(testSet)\n",
    "\n",
    "# Evaluate the model performance using the F1 metric.\n",
    "predictionAndLabels = nnResult.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "print(\"F1:\" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Non-normalized features:** F1:0.638296770979\n",
    "\n",
    "**Normalized features:** F1:0.705950405435\n",
    "\n",
    "This indeed proves the hypothesis stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Show the correlation matrix.\n",
    "original_dataset.select(features).toPandas().corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From this we can deduce that some features are correlated (mostly derrived features with primitive features). Again, as with the normalization of features. Our experiments that about 8-11 features are correlated. As feature normalization might speed up the training process (getting closer to the global or local minima), so might reducing the dimensionality of the input features. One way to achieve is to apply feature selection, i.e., the removal of features. However, other techniques aim at reducing said dimensionality while still representing the same amount of information.\n",
    "\n",
    "One of the techniques which accomplishes that behavior is called Principal Component Analysis or PCA (https://en.wikipedia.org/wiki/Principal_component_analysis). Intuitively, PCA tries to fit *n* eigenvalues to represent the data. These eigenvalues are than used as features for your machine learning model. However, PCA can also be used as a dimensionality reduction method to visualize your data. But that is outside the scope of this tutorial. More on PCA: https://www.quora.com/What-is-an-intuitive-explanation-for-PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "# Define the number of desired principal components.\n",
    "nPrincipalComponents = 19\n",
    "# Define a PCA estimator and model.\n",
    "pca = PCA(k=nPrincipalComponents, inputCol=\"features_normalized\", outputCol=\"pca_features\")\n",
    "pcaModel = pca.fit(normalized_dataset)\n",
    "\n",
    "pca_dataset = pcaModel.transform(normalized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingSet, testSet) = pca_dataset.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Define the structure of the Neural Network.\n",
    "numFeatures    = nPrincipalComponents\n",
    "numClasses     = 2 # s, b\n",
    "layers         = [numFeatures, 10, numClasses]\n",
    "\n",
    "# Define the learning algorithm (estimator).\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=5, blockSize=100000 ,layers=layers,\\\n",
    "                                         seed=1234L, featuresCol=\"pca_features\")\n",
    "# Train the Neural Network on the training set.\n",
    "nnModel = trainer.fit(trainingSet)\n",
    "nnResult = nnModel.transform(testSet)\n",
    "\n",
    "# Evaluate the model performance using the F1 metric.\n",
    "predictionAndLabels = nnResult.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "print(\"F1:\" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see there is only a very small increase in model performance. However, I would argue, this is mostly due to the small Neural Network model. The nice thing about these Neural Networks is that they will construct features in the hidden layer themselves. So any feature engineering attempts will not benifit the learning process a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
